{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains the training for the WSD classification about social media context. It uses a BERT-based pretrained model for Catalan, from HuggingFace (https://huggingface.co/projecte-aina/roberta-large-ca-v2)\n",
    "\n",
    "**NOTE**: the data used here comes from a previous script that cleaned and filtered it -> *Data_handling.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laia/VS Workspace/TFM/tfmvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-large-ca-v2 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading RoBERTa on device mps\n"
     ]
    }
   ],
   "source": [
    "# create roberta model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('projecte-aina/roberta-large-ca-v2')\n",
    "roberta = AutoModel.from_pretrained('projecte-aina/roberta-large-ca-v2',\n",
    "                                               output_hidden_states = True, # Whether the model returns all hidden-states\n",
    "                                               )\n",
    "roberta.eval()\n",
    "\n",
    "if torch.cuda.is_available(): # intel processor GPU\n",
    "  device='cuda'\n",
    "elif torch.backends.mps.is_available(): # apple silicon GPU\n",
    "  device='mps'\n",
    "else:\n",
    "  device='cpu' # CPU\n",
    "roberta.to(device)\n",
    "print(f\"Finished loading RoBERTa on device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names\n",
    "folderName = '../Data/' # We are in a subfolder\n",
    "fileName1 = 'cleanDataset.csv'\n",
    "fileName2 = 'Manual-partial_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from files\n",
    "df_init = pd.read_csv(folderName+fileName1, sep=\";\", index_col=0)\n",
    "df_ann = pd.read_csv(folderName+fileName2, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "4  1619642801406509056    retuitar   \n",
       "6  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...   \n",
       "2                  perqu√®, retuitar? perque fa falta   \n",
       "4  retuit si tu tamb√© creus que tampoc s'ha de re...   \n",
       "6  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "4  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "6  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  \n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...  \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...  \n",
       "2                  perqu√®, retuitar? perque fa falta  \n",
       "4  retuit si tu tamb√© creus que tampoc s'ha de re...  \n",
       "6  @kanen49 si us plau, deixa de retuitar aquests...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_init.shape)\n",
    "df_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1457, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>socialMediaSense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619666435776864256</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>en contra de retuitar genocides, per molt suc√≥...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619666435776864256    retuitar   \n",
       "4  1619642801406509056    retuitar   \n",
       "\n",
       "                                                text  socialMediaSense  \n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0  \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...               1.0  \n",
       "2                  perqu√®, retuitar? perque fa falta               1.0  \n",
       "3  en contra de retuitar genocides, per molt suc√≥...               1.0  \n",
       "4  retuit si tu tamb√© creus que tampoc s'ha de re...               1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_ann.shape)\n",
    "df_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DFs into the first. From the second, we only want to keep the 'socialMediaSense' column\n",
    "df = pd.merge(df_init, df_ann[['id', 'socialMediaSense']], \"inner\", on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619642801406509056    retuitar   \n",
       "4  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...   \n",
       "2                  perqu√®, retuitar? perque fa falta   \n",
       "3  retuit si tu tamb√© creus que tampoc s'ha de re...   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  socialMediaSense  \n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0  \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...               1.0  \n",
       "2                  perqu√®, retuitar? perque fa falta               1.0  \n",
       "3  retuit si tu tamb√© creus que tampoc s'ha de re...               1.0  \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows annotated with social media sense\n",
    "df_lab = df[~(df['socialMediaSense'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 158, 1.0: 130})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_lab['socialMediaSense'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id searchQuery  \\\n",
      "0  1619677524967190528    repiulet   \n",
      "1  1620168513376894976    retuitar   \n",
      "2  1619742793383170048    retuitar   \n",
      "3  1619642801406509056    retuitar   \n",
      "4  1619493816993718272    retuitar   \n",
      "\n",
      "                                                text  \\\n",
      "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
      "1  podeu demanar la dimissi√≥ de sigfrid gras sens...   \n",
      "2                  perqu√®, retuitar? perque fa falta   \n",
      "3  retuit si tu tamb√© creus que tampoc s'ha de re...   \n",
      "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
      "\n",
      "                   timestamp   type_borrowing  \\\n",
      "0  2023-01-29 12:43:00+00:00           Calque   \n",
      "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
      "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
      "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
      "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
      "\n",
      "                                           cleanText  socialMediaSense  \\\n",
      "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0   \n",
      "1  podeu demanar la dimissi√≥ de sigfrid gras sens...               1.0   \n",
      "2                  perqu√®, retuitar? perque fa falta               1.0   \n",
      "3  retuit si tu tamb√© creus que tampoc s'ha de re...               1.0   \n",
      "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0   \n",
      "\n",
      "                                          cls_vector  \n",
      "0  [0.10117894, -0.23830476, 0.17808442, 0.035533...  \n",
      "1  [0.24353136, -0.2335331, 0.12269226, 0.0489439...  \n",
      "2  [0.13093077, -0.22990246, 0.11809923, -0.09822...  \n",
      "3  [0.20563349, -0.34878263, 0.10538846, -0.17445...  \n",
      "4  [0.24767199, -0.034266822, -0.0022907257, -0.0...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/fr7ssm7s57z_7psd2b6ddp9r0000gp/T/ipykernel_32315/1235461960.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lab[\"cls_vector\"] = df_lab[\"text\"].apply(lambda x: get_cls_token(x))\n"
     ]
    }
   ],
   "source": [
    "# To train (or fit) our logistic regression, we need the value of CLS token vectors\n",
    "def get_cls_token(text):\n",
    "  # A function which extracts the CLS vector representation for any text\n",
    "\n",
    "  # first the text is tokenized\n",
    "  tokenized_text = tokenizer(text, return_tensors=\"pt\")\n",
    "  # we move tokenized to our device (gpu) so that the model can access them\n",
    "  tokenized_text.to(device)\n",
    "  with torch.no_grad():\n",
    "    # we pass all the tokens through the model, which outputs a vector representation for each word\n",
    "    outputs = roberta(**tokenized_text)\n",
    "\n",
    "  # Note (for people interested in technicalities): last_hidden_state has three dimension.\n",
    "  #     The first is the batch. If we give the model multiple sentences they would be listed here. As we only input one sentence, we can select it (0).\n",
    "  #     The second is the tokens in a sentence. Here we only take the first (0th) token which is CLS\n",
    "  #     The final one are the n dimensions of the embedding. w2vec represented each word with 300 values. Can you check how many there are here?\n",
    "  #     \":\" means we're taking all values\n",
    "  return outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
    "\n",
    "cls_vectors=[]\n",
    "df_lab[\"cls_vector\"] = df_lab[\"text\"].apply(lambda x: get_cls_token(x))\n",
    "\n",
    "print(df_lab.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - test dataset split (80-20 split) - keep the balance of the labels equal in both datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_lab[\"cls_vector\"], df_lab[\"socialMediaSense\"], test_size=0.2, random_state=42, stratify=df_lab[\"socialMediaSense\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((230,), (58,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression on CLS vectors to predict social media sense\n",
    "# We get our X (features) and our y (classes) from the previous split\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000) # simple LR\n",
    "#model = LogisticRegression(class_weight='balanced', max_iter=1000) # Weighted LR - when the distribution of labels is not balanced\n",
    "\n",
    "model = model.fit(X_train.tolist(), y_train) # fit the model to the data\n",
    "\n",
    "predictions_train = model.predict(X_train.tolist()) # produce predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fitted logistic regression IN TRAINING: 0.9478260869565217\n",
      "F1 score fitted logistic regression IN TRAINING: 0.9423076923076923\n",
      "socialMediaSense  0.0  1.0\n",
      "row_0                     \n",
      "0.0               120    6\n",
      "1.0                 6   98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate quality of classification for TRAINING dataset\n",
    "accuracy= accuracy_score(y_train, predictions_train)\n",
    "print(f'Accuracy fitted logistic regression IN TRAINING: {accuracy}')\n",
    "\n",
    "f1_score_testing = f1_score(y_train, predictions_train)\n",
    "print(f'F1 score fitted logistic regression IN TRAINING: {f1_score_testing}')\n",
    "\n",
    "confusionMatrixTest = pd.crosstab(predictions_train, y_train)\n",
    "print(confusionMatrixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try our model with the test data\n",
    "# We get our X (features) from the previous split\n",
    "predictions_test = model.predict(X_test.tolist()) # produce predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fitted logistic regression IN TESTING: 0.7413793103448276\n",
      "F1 score fitted logistic regression IN TESTING: 0.6666666666666666\n",
      "socialMediaSense  0.0  1.0\n",
      "row_0                     \n",
      "0.0                28   11\n",
      "1.0                 4   15\n"
     ]
    }
   ],
   "source": [
    "# Evaluate quality of classification for TEST dataset\n",
    "accuracy= accuracy_score(y_test, predictions_test)\n",
    "print(f'Accuracy fitted logistic regression IN TESTING: {accuracy}')\n",
    "\n",
    "f1_score_testing = f1_score(y_test, predictions_test)\n",
    "print(f'F1 score fitted logistic regression IN TESTING: {f1_score_testing}')\n",
    "\n",
    "confusionMatrixTest = pd.crosstab(predictions_test, y_test)\n",
    "print(confusionMatrixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision in Testing: 0.7894736842105263\n",
      "Recall in Testing: 0.5769230769230769\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision in Testing: {precision_score(y_test, predictions_test)}\")\n",
    "print(f\"Recall in Testing: {recall_score(y_test, predictions_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT      0.718     0.875     0.789        32\n",
      "         SMS      0.789     0.577     0.667        26\n",
      "\n",
      "    accuracy                          0.741        58\n",
      "   macro avg      0.754     0.726     0.728        58\n",
      "weighted avg      0.750     0.741     0.734        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of the main metrics\n",
    "print(\"Classification Report for the model\")\n",
    "print(classification_report(y_test, predictions_test, target_names=['NOT', 'SMS'], digits=3)) # SMS: Social Media Sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANNOTATE UNLABELED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1620168598974267392</td>\n",
       "      <td>respondre</td>\n",
       "      <td>ui, he llegit cada tuit aquest mat√≠...\\ni mira...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>ui, he llegit cada tuit aquest mat√≠... i mira ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1620181893898715136</td>\n",
       "      <td>post</td>\n",
       "      <td>ella's post üòî</td>\n",
       "      <td>2023-01-30 22:07:00+00:00</td>\n",
       "      <td>Direct borrowing</td>\n",
       "      <td>ella's post üòî</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1620140388890849280</td>\n",
       "      <td>comentar</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton\\nenhorabo...</td>\n",
       "      <td>2023-01-30 19:22:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton enhorabon...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1620127589808615424</td>\n",
       "      <td>comentar</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>2023-01-30 18:31:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1620123643425472512</td>\n",
       "      <td>comentar</td>\n",
       "      <td>üí£ n√∫ria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>2023-01-30 18:15:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>üí£ n√∫ria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id searchQuery  \\\n",
       "127  1620168598974267392   respondre   \n",
       "164  1620181893898715136        post   \n",
       "290  1620140388890849280    comentar   \n",
       "291  1620127589808615424    comentar   \n",
       "292  1620123643425472512    comentar   \n",
       "\n",
       "                                                  text  \\\n",
       "127  ui, he llegit cada tuit aquest mat√≠...\\ni mira...   \n",
       "164                                      ella's post üòî   \n",
       "290  @estelsiplanetes admirad, joan anton\\nenhorabo...   \n",
       "291  us volia comentar que avui s'ha estrenat aques...   \n",
       "292  üí£ n√∫ria roca denuncia que els fans de shakira ...   \n",
       "\n",
       "                     timestamp    type_borrowing  \\\n",
       "127  2023-01-30 21:14:00+00:00            Calque   \n",
       "164  2023-01-30 22:07:00+00:00  Direct borrowing   \n",
       "290  2023-01-30 19:22:00+00:00            Calque   \n",
       "291  2023-01-30 18:31:00+00:00            Calque   \n",
       "292  2023-01-30 18:15:00+00:00            Calque   \n",
       "\n",
       "                                             cleanText  socialMediaSense  \n",
       "127  ui, he llegit cada tuit aquest mat√≠... i mira ...               NaN  \n",
       "164                                      ella's post üòî               NaN  \n",
       "290  @estelsiplanetes admirad, joan anton enhorabon...               NaN  \n",
       "291  us volia comentar que avui s'ha estrenat aques...               NaN  \n",
       "292  üí£ n√∫ria roca denuncia que els fans de shakira ...               NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annotate the unlabeled part of the dataset\n",
    "df_not = df[(df['socialMediaSense'].isna())]\n",
    "print(df_not.shape)\n",
    "df_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/fr7ssm7s57z_7psd2b6ddp9r0000gp/T/ipykernel_32315/2312342491.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not[\"cls_vector\"] = df_not[\"text\"].apply(lambda x: get_cls_token(x))\n"
     ]
    }
   ],
   "source": [
    "# Generate CLS tokens for the texts\n",
    "cls_vectors=[]\n",
    "df_not[\"cls_vector\"] = df_not[\"text\"].apply(lambda x: get_cls_token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/fr7ssm7s57z_7psd2b6ddp9r0000gp/T/ipykernel_32315/4069637629.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not['socialMediaSense'] = predictions_prod\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the unlabeled rows\n",
    "# We get our X (features)\n",
    "X_prod = df_not[\"cls_vector\"].tolist()\n",
    "\n",
    "predictions_prod = model.predict(X_prod) # produce predictions\n",
    "df_not['socialMediaSense'] = predictions_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "      <th>cls_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1620168598974267392</td>\n",
       "      <td>respondre</td>\n",
       "      <td>ui, he llegit cada tuit aquest mat√≠...\\ni mira...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>ui, he llegit cada tuit aquest mat√≠... i mira ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.094049096, -0.10130556, 0.3584217, 0.103393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1620181893898715136</td>\n",
       "      <td>post</td>\n",
       "      <td>ella's post üòî</td>\n",
       "      <td>2023-01-30 22:07:00+00:00</td>\n",
       "      <td>Direct borrowing</td>\n",
       "      <td>ella's post üòî</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.16650769, -0.27861863, 0.02536476, -0.05767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1620140388890849280</td>\n",
       "      <td>comentar</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton\\nenhorabo...</td>\n",
       "      <td>2023-01-30 19:22:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton enhorabon...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.27231136, 0.10775298, 0.1529417, 0.06056674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1620127589808615424</td>\n",
       "      <td>comentar</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>2023-01-30 18:31:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.16063462, -0.06442083, 0.10596745, -0.12750...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1620123643425472512</td>\n",
       "      <td>comentar</td>\n",
       "      <td>üí£ n√∫ria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>2023-01-30 18:15:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>üí£ n√∫ria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.16521722, 0.05898673, 0.025104355, -0.16138...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id searchQuery  \\\n",
       "127  1620168598974267392   respondre   \n",
       "164  1620181893898715136        post   \n",
       "290  1620140388890849280    comentar   \n",
       "291  1620127589808615424    comentar   \n",
       "292  1620123643425472512    comentar   \n",
       "\n",
       "                                                  text  \\\n",
       "127  ui, he llegit cada tuit aquest mat√≠...\\ni mira...   \n",
       "164                                      ella's post üòî   \n",
       "290  @estelsiplanetes admirad, joan anton\\nenhorabo...   \n",
       "291  us volia comentar que avui s'ha estrenat aques...   \n",
       "292  üí£ n√∫ria roca denuncia que els fans de shakira ...   \n",
       "\n",
       "                     timestamp    type_borrowing  \\\n",
       "127  2023-01-30 21:14:00+00:00            Calque   \n",
       "164  2023-01-30 22:07:00+00:00  Direct borrowing   \n",
       "290  2023-01-30 19:22:00+00:00            Calque   \n",
       "291  2023-01-30 18:31:00+00:00            Calque   \n",
       "292  2023-01-30 18:15:00+00:00            Calque   \n",
       "\n",
       "                                             cleanText  socialMediaSense  \\\n",
       "127  ui, he llegit cada tuit aquest mat√≠... i mira ...               1.0   \n",
       "164                                      ella's post üòî               1.0   \n",
       "290  @estelsiplanetes admirad, joan anton enhorabon...               0.0   \n",
       "291  us volia comentar que avui s'ha estrenat aques...               0.0   \n",
       "292  üí£ n√∫ria roca denuncia que els fans de shakira ...               1.0   \n",
       "\n",
       "                                            cls_vector  \n",
       "127  [0.094049096, -0.10130556, 0.3584217, 0.103393...  \n",
       "164  [0.16650769, -0.27861863, 0.02536476, -0.05767...  \n",
       "290  [0.27231136, 0.10775298, 0.1529417, 0.06056674...  \n",
       "291  [0.16063462, -0.06442083, 0.10596745, -0.12750...  \n",
       "292  [0.16521722, 0.05898673, 0.025104355, -0.16138...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_not.shape)\n",
    "df_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "      <th>cls_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.10117894, -0.23830476, 0.17808442, 0.035533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24353136, -0.2335331, 0.12269226, 0.0489439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.13093077, -0.22990246, 0.11809923, -0.09822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.20563349, -0.34878263, 0.10538846, -0.17445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24767199, -0.034266822, -0.0022907257, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619642801406509056    retuitar   \n",
       "4  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...   \n",
       "2                  perqu√®, retuitar? perque fa falta   \n",
       "3  retuit si tu tamb√© creus que tampoc s'ha de re...   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  socialMediaSense  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0   \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...               1.0   \n",
       "2                  perqu√®, retuitar? perque fa falta               1.0   \n",
       "3  retuit si tu tamb√© creus que tampoc s'ha de re...               1.0   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0   \n",
       "\n",
       "                                          cls_vector  \n",
       "0  [0.10117894, -0.23830476, 0.17808442, 0.035533...  \n",
       "1  [0.24353136, -0.2335331, 0.12269226, 0.0489439...  \n",
       "2  [0.13093077, -0.22990246, 0.11809923, -0.09822...  \n",
       "3  [0.20563349, -0.34878263, 0.10538846, -0.17445...  \n",
       "4  [0.24767199, -0.034266822, -0.0022907257, -0.0...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the DF with previously annotated data and the DF with the automatic labeling\n",
    "df_concat = pd.concat([df_lab, df_not], axis=0)\n",
    "print(df_concat.shape)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "      <th>cls_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.10117894, -0.23830476, 0.17808442, 0.035533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissi√≥ de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24353136, -0.2335331, 0.12269226, 0.0489439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perqu√®, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.13093077, -0.22990246, 0.11809923, -0.09822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu tamb√© creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.20563349, -0.34878263, 0.10538846, -0.17445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24767199, -0.034266822, -0.0022907257, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619642801406509056    retuitar   \n",
       "4  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...   \n",
       "2                  perqu√®, retuitar? perque fa falta   \n",
       "3  retuit si tu tamb√© creus que tampoc s'ha de re...   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  socialMediaSense  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0   \n",
       "1  podeu demanar la dimissi√≥ de sigfrid gras sens...               1.0   \n",
       "2                  perqu√®, retuitar? perque fa falta               1.0   \n",
       "3  retuit si tu tamb√© creus que tampoc s'ha de re...               1.0   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0   \n",
       "\n",
       "                                          cls_vector  \n",
       "0  [0.10117894, -0.23830476, 0.17808442, 0.035533...  \n",
       "1  [0.24353136, -0.2335331, 0.12269226, 0.0489439...  \n",
       "2  [0.13093077, -0.22990246, 0.11809923, -0.09822...  \n",
       "3  [0.20563349, -0.34878263, 0.10538846, -0.17445...  \n",
       "4  [0.24767199, -0.034266822, -0.0022907257, -0.0...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter: leave only rows that have a social media sense\n",
    "df_sms = df_concat[df_concat['socialMediaSense'] == 1.0]\n",
    "print(df_sms.shape)\n",
    "df_sms.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
