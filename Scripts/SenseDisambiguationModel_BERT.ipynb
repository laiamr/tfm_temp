{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains the training for the WSD classification about social media context. It uses a BERT-based pretrained model for Catalan, from HuggingFace (https://huggingface.co/projecte-aina/roberta-large-ca-v2)\n",
    "\n",
    "**NOTE**: the data used here comes from a previous script that cleaned and filtered it -> *Data_handling.ipynb*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/laia/VS Workspace/TFM/tfmvenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at projecte-aina/roberta-large-ca-v2 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading RoBERTa on device mps\n"
     ]
    }
   ],
   "source": [
    "# create roberta model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('projecte-aina/roberta-large-ca-v2')\n",
    "roberta = AutoModel.from_pretrained('projecte-aina/roberta-large-ca-v2',\n",
    "                                               output_hidden_states = True, # Whether the model returns all hidden-states\n",
    "                                               )\n",
    "roberta.eval()\n",
    "\n",
    "if torch.cuda.is_available(): # intel processor GPU\n",
    "  device='cuda'\n",
    "elif torch.backends.mps.is_available(): # apple silicon GPU\n",
    "  device='mps'\n",
    "else:\n",
    "  device='cpu' # CPU\n",
    "roberta.to(device)\n",
    "print(f\"Finished loading RoBERTa on device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File names\n",
    "folderName = '../Data/' # We are in a subfolder\n",
    "fileName1 = 'cleanDataset.csv'\n",
    "fileName2 = 'Manual-partial_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from files\n",
    "df_init = pd.read_csv(folderName+fileName1, sep=\";\", index_col=0)\n",
    "df_ann = pd.read_csv(folderName+fileName2, sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "4  1619642801406509056    retuitar   \n",
       "6  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...   \n",
       "2                  perquè, retuitar? perque fa falta   \n",
       "4  retuit si tu també creus que tampoc s'ha de re...   \n",
       "6  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "4  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "6  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  \n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...  \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...  \n",
       "2                  perquè, retuitar? perque fa falta  \n",
       "4  retuit si tu també creus que tampoc s'ha de re...  \n",
       "6  @kanen49 si us plau, deixa de retuitar aquests...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_init.shape)\n",
    "df_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1457, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>socialMediaSense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619666435776864256</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>en contra de retuitar genocides, per molt sucó...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619666435776864256    retuitar   \n",
       "4  1619642801406509056    retuitar   \n",
       "\n",
       "                                                text  socialMediaSense  \n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0  \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...               1.0  \n",
       "2                  perquè, retuitar? perque fa falta               1.0  \n",
       "3  en contra de retuitar genocides, per molt sucó...               1.0  \n",
       "4  retuit si tu també creus que tampoc s'ha de re...               1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_ann.shape)\n",
    "df_ann.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two DFs into the first. From the second, we only want to keep the 'socialMediaSense' column\n",
    "df = pd.merge(df_init, df_ann[['id', 'socialMediaSense']], \"inner\", on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619642801406509056    retuitar   \n",
       "4  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...   \n",
       "2                  perquè, retuitar? perque fa falta   \n",
       "3  retuit si tu també creus que tampoc s'ha de re...   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  socialMediaSense  \n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0  \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...               1.0  \n",
       "2                  perquè, retuitar? perque fa falta               1.0  \n",
       "3  retuit si tu també creus que tampoc s'ha de re...               1.0  \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows annotated with social media sense\n",
    "df_lab = df[~(df['socialMediaSense'].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 158, 1.0: 130})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_lab['socialMediaSense'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAIN MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id searchQuery  \\\n",
      "0  1619677524967190528    repiulet   \n",
      "1  1620168513376894976    retuitar   \n",
      "2  1619742793383170048    retuitar   \n",
      "3  1619642801406509056    retuitar   \n",
      "4  1619493816993718272    retuitar   \n",
      "\n",
      "                                                text  \\\n",
      "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
      "1  podeu demanar la dimissió de sigfrid gras sens...   \n",
      "2                  perquè, retuitar? perque fa falta   \n",
      "3  retuit si tu també creus que tampoc s'ha de re...   \n",
      "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
      "\n",
      "                   timestamp   type_borrowing  \\\n",
      "0  2023-01-29 12:43:00+00:00           Calque   \n",
      "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
      "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
      "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
      "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
      "\n",
      "                                           cleanText  socialMediaSense  \\\n",
      "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0   \n",
      "1  podeu demanar la dimissió de sigfrid gras sens...               1.0   \n",
      "2                  perquè, retuitar? perque fa falta               1.0   \n",
      "3  retuit si tu també creus que tampoc s'ha de re...               1.0   \n",
      "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0   \n",
      "\n",
      "                                          cls_vector  \n",
      "0  [0.10117894, -0.23830476, 0.17808442, 0.035533...  \n",
      "1  [0.24353136, -0.2335331, 0.12269226, 0.0489439...  \n",
      "2  [0.13093077, -0.22990246, 0.11809923, -0.09822...  \n",
      "3  [0.20563349, -0.34878263, 0.10538846, -0.17445...  \n",
      "4  [0.24767199, -0.034266822, -0.0022907257, -0.0...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/fr7ssm7s57z_7psd2b6ddp9r0000gp/T/ipykernel_32315/1235461960.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lab[\"cls_vector\"] = df_lab[\"text\"].apply(lambda x: get_cls_token(x))\n"
     ]
    }
   ],
   "source": [
    "# To train (or fit) our logistic regression, we need the value of CLS token vectors\n",
    "def get_cls_token(text):\n",
    "  # A function which extracts the CLS vector representation for any text\n",
    "\n",
    "  # first the text is tokenized\n",
    "  tokenized_text = tokenizer(text, return_tensors=\"pt\")\n",
    "  # we move tokenized to our device (gpu) so that the model can access them\n",
    "  tokenized_text.to(device)\n",
    "  with torch.no_grad():\n",
    "    # we pass all the tokens through the model, which outputs a vector representation for each word\n",
    "    outputs = roberta(**tokenized_text)\n",
    "\n",
    "  # Note (for people interested in technicalities): last_hidden_state has three dimension.\n",
    "  #     The first is the batch. If we give the model multiple sentences they would be listed here. As we only input one sentence, we can select it (0).\n",
    "  #     The second is the tokens in a sentence. Here we only take the first (0th) token which is CLS\n",
    "  #     The final one are the n dimensions of the embedding. w2vec represented each word with 300 values. Can you check how many there are here?\n",
    "  #     \":\" means we're taking all values\n",
    "  return outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
    "\n",
    "cls_vectors=[]\n",
    "df_lab[\"cls_vector\"] = df_lab[\"text\"].apply(lambda x: get_cls_token(x))\n",
    "\n",
    "print(df_lab.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - test dataset split (80-20 split) - keep the balance of the labels equal in both datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_lab[\"cls_vector\"], df_lab[\"socialMediaSense\"], test_size=0.2, random_state=42, stratify=df_lab[\"socialMediaSense\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((230,), (58,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression on CLS vectors to predict social media sense\n",
    "# We get our X (features) and our y (classes) from the previous split\n",
    "\n",
    "# Initialize the model\n",
    "model = LogisticRegression(max_iter=1000) # simple LR\n",
    "#model = LogisticRegression(class_weight='balanced', max_iter=1000) # Weighted LR - when the distribution of labels is not balanced\n",
    "\n",
    "model = model.fit(X_train.tolist(), y_train) # fit the model to the data\n",
    "\n",
    "predictions_train = model.predict(X_train.tolist()) # produce predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fitted logistic regression IN TRAINING: 0.9478260869565217\n",
      "F1 score fitted logistic regression IN TRAINING: 0.9423076923076923\n",
      "socialMediaSense  0.0  1.0\n",
      "row_0                     \n",
      "0.0               120    6\n",
      "1.0                 6   98\n"
     ]
    }
   ],
   "source": [
    "# Evaluate quality of classification for TRAINING dataset\n",
    "accuracy= accuracy_score(y_train, predictions_train)\n",
    "print(f'Accuracy fitted logistic regression IN TRAINING: {accuracy}')\n",
    "\n",
    "f1_score_testing = f1_score(y_train, predictions_train)\n",
    "print(f'F1 score fitted logistic regression IN TRAINING: {f1_score_testing}')\n",
    "\n",
    "confusionMatrixTest = pd.crosstab(predictions_train, y_train)\n",
    "print(confusionMatrixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try our model with the test data\n",
    "# We get our X (features) from the previous split\n",
    "predictions_test = model.predict(X_test.tolist()) # produce predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy fitted logistic regression IN TESTING: 0.7413793103448276\n",
      "F1 score fitted logistic regression IN TESTING: 0.6666666666666666\n",
      "socialMediaSense  0.0  1.0\n",
      "row_0                     \n",
      "0.0                28   11\n",
      "1.0                 4   15\n"
     ]
    }
   ],
   "source": [
    "# Evaluate quality of classification for TEST dataset\n",
    "accuracy= accuracy_score(y_test, predictions_test)\n",
    "print(f'Accuracy fitted logistic regression IN TESTING: {accuracy}')\n",
    "\n",
    "f1_score_testing = f1_score(y_test, predictions_test)\n",
    "print(f'F1 score fitted logistic regression IN TESTING: {f1_score_testing}')\n",
    "\n",
    "confusionMatrixTest = pd.crosstab(predictions_test, y_test)\n",
    "print(confusionMatrixTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision in Testing: 0.7894736842105263\n",
      "Recall in Testing: 0.5769230769230769\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision in Testing: {precision_score(y_test, predictions_test)}\")\n",
    "print(f\"Recall in Testing: {recall_score(y_test, predictions_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NOT      0.718     0.875     0.789        32\n",
      "         SMS      0.789     0.577     0.667        26\n",
      "\n",
      "    accuracy                          0.741        58\n",
      "   macro avg      0.754     0.726     0.728        58\n",
      "weighted avg      0.750     0.741     0.734        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Summary of the main metrics\n",
    "print(\"Classification Report for the model\")\n",
    "print(classification_report(y_test, predictions_test, target_names=['NOT', 'SMS'], digits=3)) # SMS: Social Media Sense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANNOTATE UNLABELED DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1620168598974267392</td>\n",
       "      <td>respondre</td>\n",
       "      <td>ui, he llegit cada tuit aquest matí...\\ni mira...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>ui, he llegit cada tuit aquest matí... i mira ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1620181893898715136</td>\n",
       "      <td>post</td>\n",
       "      <td>ella's post 😔</td>\n",
       "      <td>2023-01-30 22:07:00+00:00</td>\n",
       "      <td>Direct borrowing</td>\n",
       "      <td>ella's post 😔</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1620140388890849280</td>\n",
       "      <td>comentar</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton\\nenhorabo...</td>\n",
       "      <td>2023-01-30 19:22:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton enhorabon...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1620127589808615424</td>\n",
       "      <td>comentar</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>2023-01-30 18:31:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1620123643425472512</td>\n",
       "      <td>comentar</td>\n",
       "      <td>💣 núria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>2023-01-30 18:15:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>💣 núria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id searchQuery  \\\n",
       "127  1620168598974267392   respondre   \n",
       "164  1620181893898715136        post   \n",
       "290  1620140388890849280    comentar   \n",
       "291  1620127589808615424    comentar   \n",
       "292  1620123643425472512    comentar   \n",
       "\n",
       "                                                  text  \\\n",
       "127  ui, he llegit cada tuit aquest matí...\\ni mira...   \n",
       "164                                      ella's post 😔   \n",
       "290  @estelsiplanetes admirad, joan anton\\nenhorabo...   \n",
       "291  us volia comentar que avui s'ha estrenat aques...   \n",
       "292  💣 núria roca denuncia que els fans de shakira ...   \n",
       "\n",
       "                     timestamp    type_borrowing  \\\n",
       "127  2023-01-30 21:14:00+00:00            Calque   \n",
       "164  2023-01-30 22:07:00+00:00  Direct borrowing   \n",
       "290  2023-01-30 19:22:00+00:00            Calque   \n",
       "291  2023-01-30 18:31:00+00:00            Calque   \n",
       "292  2023-01-30 18:15:00+00:00            Calque   \n",
       "\n",
       "                                             cleanText  socialMediaSense  \n",
       "127  ui, he llegit cada tuit aquest matí... i mira ...               NaN  \n",
       "164                                      ella's post 😔               NaN  \n",
       "290  @estelsiplanetes admirad, joan anton enhorabon...               NaN  \n",
       "291  us volia comentar que avui s'ha estrenat aques...               NaN  \n",
       "292  💣 núria roca denuncia que els fans de shakira ...               NaN  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annotate the unlabeled part of the dataset\n",
    "df_not = df[(df['socialMediaSense'].isna())]\n",
    "print(df_not.shape)\n",
    "df_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/fr7ssm7s57z_7psd2b6ddp9r0000gp/T/ipykernel_32315/2312342491.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not[\"cls_vector\"] = df_not[\"text\"].apply(lambda x: get_cls_token(x))\n"
     ]
    }
   ],
   "source": [
    "# Generate CLS tokens for the texts\n",
    "cls_vectors=[]\n",
    "df_not[\"cls_vector\"] = df_not[\"text\"].apply(lambda x: get_cls_token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n5/fr7ssm7s57z_7psd2b6ddp9r0000gp/T/ipykernel_32315/4069637629.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_not['socialMediaSense'] = predictions_prod\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions for the unlabeled rows\n",
    "# We get our X (features)\n",
    "X_prod = df_not[\"cls_vector\"].tolist()\n",
    "\n",
    "predictions_prod = model.predict(X_prod) # produce predictions\n",
    "df_not['socialMediaSense'] = predictions_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1121, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "      <th>cls_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>1620168598974267392</td>\n",
       "      <td>respondre</td>\n",
       "      <td>ui, he llegit cada tuit aquest matí...\\ni mira...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>ui, he llegit cada tuit aquest matí... i mira ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.094049096, -0.10130556, 0.3584217, 0.103393...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>1620181893898715136</td>\n",
       "      <td>post</td>\n",
       "      <td>ella's post 😔</td>\n",
       "      <td>2023-01-30 22:07:00+00:00</td>\n",
       "      <td>Direct borrowing</td>\n",
       "      <td>ella's post 😔</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.16650769, -0.27861863, 0.02536476, -0.05767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1620140388890849280</td>\n",
       "      <td>comentar</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton\\nenhorabo...</td>\n",
       "      <td>2023-01-30 19:22:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>@estelsiplanetes admirad, joan anton enhorabon...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.27231136, 0.10775298, 0.1529417, 0.06056674...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1620127589808615424</td>\n",
       "      <td>comentar</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>2023-01-30 18:31:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>us volia comentar que avui s'ha estrenat aques...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.16063462, -0.06442083, 0.10596745, -0.12750...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1620123643425472512</td>\n",
       "      <td>comentar</td>\n",
       "      <td>💣 núria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>2023-01-30 18:15:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>💣 núria roca denuncia que els fans de shakira ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.16521722, 0.05898673, 0.025104355, -0.16138...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id searchQuery  \\\n",
       "127  1620168598974267392   respondre   \n",
       "164  1620181893898715136        post   \n",
       "290  1620140388890849280    comentar   \n",
       "291  1620127589808615424    comentar   \n",
       "292  1620123643425472512    comentar   \n",
       "\n",
       "                                                  text  \\\n",
       "127  ui, he llegit cada tuit aquest matí...\\ni mira...   \n",
       "164                                      ella's post 😔   \n",
       "290  @estelsiplanetes admirad, joan anton\\nenhorabo...   \n",
       "291  us volia comentar que avui s'ha estrenat aques...   \n",
       "292  💣 núria roca denuncia que els fans de shakira ...   \n",
       "\n",
       "                     timestamp    type_borrowing  \\\n",
       "127  2023-01-30 21:14:00+00:00            Calque   \n",
       "164  2023-01-30 22:07:00+00:00  Direct borrowing   \n",
       "290  2023-01-30 19:22:00+00:00            Calque   \n",
       "291  2023-01-30 18:31:00+00:00            Calque   \n",
       "292  2023-01-30 18:15:00+00:00            Calque   \n",
       "\n",
       "                                             cleanText  socialMediaSense  \\\n",
       "127  ui, he llegit cada tuit aquest matí... i mira ...               1.0   \n",
       "164                                      ella's post 😔               1.0   \n",
       "290  @estelsiplanetes admirad, joan anton enhorabon...               0.0   \n",
       "291  us volia comentar que avui s'ha estrenat aques...               0.0   \n",
       "292  💣 núria roca denuncia que els fans de shakira ...               1.0   \n",
       "\n",
       "                                            cls_vector  \n",
       "127  [0.094049096, -0.10130556, 0.3584217, 0.103393...  \n",
       "164  [0.16650769, -0.27861863, 0.02536476, -0.05767...  \n",
       "290  [0.27231136, 0.10775298, 0.1529417, 0.06056674...  \n",
       "291  [0.16063462, -0.06442083, 0.10596745, -0.12750...  \n",
       "292  [0.16521722, 0.05898673, 0.025104355, -0.16138...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_not.shape)\n",
    "df_not.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1409, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "      <th>cls_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.10117894, -0.23830476, 0.17808442, 0.035533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24353136, -0.2335331, 0.12269226, 0.0489439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.13093077, -0.22990246, 0.11809923, -0.09822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.20563349, -0.34878263, 0.10538846, -0.17445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24767199, -0.034266822, -0.0022907257, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619642801406509056    retuitar   \n",
       "4  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...   \n",
       "2                  perquè, retuitar? perque fa falta   \n",
       "3  retuit si tu també creus que tampoc s'ha de re...   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  socialMediaSense  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0   \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...               1.0   \n",
       "2                  perquè, retuitar? perque fa falta               1.0   \n",
       "3  retuit si tu també creus que tampoc s'ha de re...               1.0   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0   \n",
       "\n",
       "                                          cls_vector  \n",
       "0  [0.10117894, -0.23830476, 0.17808442, 0.035533...  \n",
       "1  [0.24353136, -0.2335331, 0.12269226, 0.0489439...  \n",
       "2  [0.13093077, -0.22990246, 0.11809923, -0.09822...  \n",
       "3  [0.20563349, -0.34878263, 0.10538846, -0.17445...  \n",
       "4  [0.24767199, -0.034266822, -0.0022907257, -0.0...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the DF with previously annotated data and the DF with the automatic labeling\n",
    "df_concat = pd.concat([df_lab, df_not], axis=0)\n",
    "print(df_concat.shape)\n",
    "df_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(477, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>searchQuery</th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>type_borrowing</th>\n",
       "      <th>cleanText</th>\n",
       "      <th>socialMediaSense</th>\n",
       "      <th>cls_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1619677524967190528</td>\n",
       "      <td>repiulet</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>2023-01-29 12:43:00+00:00</td>\n",
       "      <td>Calque</td>\n",
       "      <td>un ruzi*, que he barrat tot d'una, vota pel me...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.10117894, -0.23830476, 0.17808442, 0.035533...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1620168513376894976</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>2023-01-30 21:14:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>podeu demanar la dimissió de sigfrid gras sens...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24353136, -0.2335331, 0.12269226, 0.0489439...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1619742793383170048</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>2023-01-29 17:02:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>perquè, retuitar? perque fa falta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.13093077, -0.22990246, 0.11809923, -0.09822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1619642801406509056</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>2023-01-29 10:25:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>retuit si tu també creus que tampoc s'ha de re...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.20563349, -0.34878263, 0.10538846, -0.17445...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1619493816993718272</td>\n",
       "      <td>retuitar</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>2023-01-29 00:33:00+00:00</td>\n",
       "      <td>Full adaptation</td>\n",
       "      <td>@kanen49 si us plau, deixa de retuitar aquests...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.24767199, -0.034266822, -0.0022907257, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id searchQuery  \\\n",
       "0  1619677524967190528    repiulet   \n",
       "1  1620168513376894976    retuitar   \n",
       "2  1619742793383170048    retuitar   \n",
       "3  1619642801406509056    retuitar   \n",
       "4  1619493816993718272    retuitar   \n",
       "\n",
       "                                                text  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...   \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...   \n",
       "2                  perquè, retuitar? perque fa falta   \n",
       "3  retuit si tu també creus que tampoc s'ha de re...   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...   \n",
       "\n",
       "                   timestamp   type_borrowing  \\\n",
       "0  2023-01-29 12:43:00+00:00           Calque   \n",
       "1  2023-01-30 21:14:00+00:00  Full adaptation   \n",
       "2  2023-01-29 17:02:00+00:00  Full adaptation   \n",
       "3  2023-01-29 10:25:00+00:00  Full adaptation   \n",
       "4  2023-01-29 00:33:00+00:00  Full adaptation   \n",
       "\n",
       "                                           cleanText  socialMediaSense  \\\n",
       "0  un ruzi*, que he barrat tot d'una, vota pel me...               1.0   \n",
       "1  podeu demanar la dimissió de sigfrid gras sens...               1.0   \n",
       "2                  perquè, retuitar? perque fa falta               1.0   \n",
       "3  retuit si tu també creus que tampoc s'ha de re...               1.0   \n",
       "4  @kanen49 si us plau, deixa de retuitar aquests...               1.0   \n",
       "\n",
       "                                          cls_vector  \n",
       "0  [0.10117894, -0.23830476, 0.17808442, 0.035533...  \n",
       "1  [0.24353136, -0.2335331, 0.12269226, 0.0489439...  \n",
       "2  [0.13093077, -0.22990246, 0.11809923, -0.09822...  \n",
       "3  [0.20563349, -0.34878263, 0.10538846, -0.17445...  \n",
       "4  [0.24767199, -0.034266822, -0.0022907257, -0.0...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter: leave only rows that have a social media sense\n",
    "df_sms = df_concat[df_concat['socialMediaSense'] == 1.0]\n",
    "print(df_sms.shape)\n",
    "df_sms.head()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
